<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Xinghan Wang</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Xinghan Wang 王星瀚
                </p>
                <p>I am a Ph.D. candidate at Wangxuan Institute of Computer Technology in Peking University, advised by Prof. <a href="http://www.muyadong.com/">Yadong Mu</a>. Prior to that, I received my B.S. degree (Summa Cum Laude) in artificial intelligence (Turing Class) from Peking University.
                </p>

                <p style="text-align:center">
                  <a href="mailto:xinghan_wang@pku.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=8fiweJYAAAAJ&hl=en&oi=ao">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Infinitywxh/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/wxh.JPG"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/wxh.JPG" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research interests lie in human motion analysis, temporal modeling and multi-modal learning.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/biomodiffuse_motivation.png" alt="b3do" width="160" style="border-style: none">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2503.06151/">
          <span class="papertitle">BioMoDiffuse: Physics-Guided Biomechanical Diffusion for Controllable and Authentic Human Motion Synthesis</span>
        </a>
        <br>
        Zixi Kang, <strong>Xinghan Wang</strong>, Yadong Mu
        <br>
        <em>arXiv</em>, 2025
        <br>
        <a href="https://arxiv.org/pdf/2503.06151">paper</a> / 
        <a href="data/kang2025bio.bib">bibtex</a>
        <br>
        <p></p>
        <p>
          A novel biomechanics-aware diffusion framework seamlessly integrating musculoskeletal dynamics with diffusion processes for authentic human motion generation.
        </p>
      </td>
    </tr>  
            
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/tmamba_motivation.png" alt="b3do" width="160" style="border-style: none">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2404.11375/">
          <span class="papertitle">Text-controlled Motion Mamba: Text-Instructed Temporal Grounding of Human Motion</span>
        </a>
        <br>
        <strong>Xinghan Wang</strong>, Zixi Kang, Yadong Mu
        <br>
        <em>arXiv</em>, 2024
        <br>
        <a href="https://arxiv.org/pdf/2404.11375">paper</a> / 
        <a href="data/wang2024text.bib">bibtex</a>
        <br>
        <p></p>
        <p>
          We introduce the text-based human motion grounding task, along with a new text-motion dataset with temporal and textual annotations. A model called TM-Mamba is proposed which can selectively propagates information using a text-controlled mechanism within the Mamba framework.
        </p>
      </td>
    </tr>  

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/tmm_motivation.png" alt="b3do" width="160" style="border-style: none">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10539295/">
          <span class="papertitle">Localized Linear Temporal Dynamics for Self-supervised Skeleton Action Recognition</span>
        </a>
        <br>
        <strong>Xinghan Wang</strong>, Yadong Mu
        <br>
        <em>IEEE Transactions on Multimedia</em>, 2024
        <br>
        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10539295">paper</a> / 
        <a href="data/wang2024localized.bib">bibtex</a>
        <br>
        <p></p>
        <p>
        A temporal contrastive learning framework for self-supervised skeleton action recognition that leverages segment-level localized linear dynamics to acquire discriminative temporal evolution patterns.
        </p>
      </td>
    </tr>  


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/cvpr23_motivation.png" alt="b3do" width="160" style="border-style: none">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Neural_Koopman_Pooling_Control-Inspired_Temporal_Dynamics_Encoding_for_Skeleton-Based_Action_CVPR_2023_paper.html">
          <span class="papertitle">Neural Koopman pooling: Control-inspired Temporal Dynamics Encoding for Skeleton-based Action Recognition</span>
        </a>
        <br>
        <strong>Xinghan Wang</strong>, Xin Xu, Yadong Mu
        <br>
        <em>CVPR</em>, 2023
        <br>
        <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Neural_Koopman_Pooling_Control-Inspired_Temporal_Dynamics_Encoding_for_Skeleton-Based_Action_CVPR_2023_paper.pdf">paper</a> / 
        <a href="https://github.com/Infinitywxh/Neural_Koopman_pooling">code</a> / 
        <a href="data/wang2023neural.bib">bibtex</a>
        <br>
        <p></p>
        <p>
        A novel parameterized high-order temporal pooling method based on Koopman theory for skeleton action recognition.
        </p>
      </td>
    </tr>  

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/cvpr20_motivation.png" alt="b3do" width="160" style="border-style: none">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Gong_Learning_Temporal_Co-Attention_Models_for_Unsupervised_Video_Action_Localization_CVPR_2020_paper.html">
          <span class="papertitle">Learning Temporal Co-attention Models for Unsupervised Video Action Localization</span>
        </a>
        <br>
        Guoqiang Gong, <strong>Xinghan Wang</strong>, Yadong Mu, Qi Tian
        <br>
        <em>CVPR</em>, 2020
        <br>
        <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Gong_Learning_Temporal_Co-Attention_Models_for_Unsupervised_Video_Action_Localization_CVPR_2020_paper.pdf">paper</a> / 
        <a href="https://github.com/GGQ1996/action_co_localization">code</a> / 
        <a href="data/gong2020learning.bib">bibtex</a>
        <br>
        <p></p>
        <p>
        A fully unsupervised framework for video action localization based on temporal co-attention, clustering and iterative optimization.
        </p>
      </td>
    </tr>  

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <h2>Education</h2>
        <p>
          <ul>
            <li>
              <div style="float:left; text-align:left">
                <b>Ph.D. candidate</b>, School of Intelligence Science and Technology,
                Peking University
              </div>
              <div style="float:right; text-align:right">2021 - present</div><br>
            </li>

            <li>
              <div style="float:left; text-align:left">
                <b>B.S.</b>, School of Electronics Engineering and Computer Science,
                Peking University
              </div>
              <div style="float:right; text-align:right">2017 - 2021</div><br>
            </li>
          </ul>
        </p>
      </td>
    </tr>
  </tbody></table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <h2>Experiences</h2>
        <p>
          <ul>
            <li>
              <div style="float:left; text-align:left">
                Large Models and Multimedia Technology Department, Kuaishou Technology, China
              </div>
              <div style="float:right; text-align:right">2024.12 - present</div><br>
            </li>
          </ul>
        </p>
      </td>
    </tr>
  </tbody></table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <h2>Academic Services</h2>
        <p>
          <ul>
            <li>Reviewer for the following conferences: NeurIPS 2022-24, ACM MM 2022-23, ICCV 2023, ICML 2024, ICLR 2024-25, ECCV 2024, AAAI 2025, CVPR 2025.</li>
            <li>Reviewer for the following journals: Transactions on Multimedia (TMM), Transactions on Pattern Analysis and Machine Intelligence (TPAMI).</li>
          </ul>
        </p>
      </td>
    </tr>
  </tbody></table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
